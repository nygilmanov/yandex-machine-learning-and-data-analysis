{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, datasets, metrics, tree,ensemble\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAADFCAYAAAAG5C2JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAmwCBJgESQA/g8nWqkPY8yb6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ebbceb8a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Display the first digit\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=digits.data\n",
    "y=digits.target\n",
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(digits.data, \n",
    "                                                                                     digits.target, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_clf(X,y,clf):\n",
    "    clf.fit(X, y)\n",
    "    scores = cross_val_score(clf, X, y, cv=10)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380719695724016"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_clf = tree.DecisionTreeClassifier()\n",
    "res=test_clf(X,y,DT_clf)\n",
    "write_answer_to_file(res,\"test1_res1.txt\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ответ в пункте 1 = 0.83361910017445717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92824278346686029"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_clf=ensemble.BaggingClassifier(base_estimator=DT_clf,n_estimators=100)\n",
    "res=test_clf(X,y,B_clf)\n",
    "write_answer_to_file(res,\"test1_res2.txt\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ответ в пункте 2 = 0.92156126960200591"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task3\n",
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на d√ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93097656824701125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_qty=math.sqrt(X.shape[1])\n",
    "B_MF_clf=ensemble.BaggingClassifier(base_estimator=DT_clf,n_estimators=100,max_features=int(params_qty))\n",
    "res=test_clf(X,y,B_MF_clf)\n",
    "write_answer_to_file(res,\"test1_res3.txt\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ответ в пункте 3 = 0.93933062852919957**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task4\n",
    "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же d√ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95730506222189859"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_MF_clf = tree.DecisionTreeClassifier(max_features='sqrt')\n",
    "B_MF2_clf=ensemble.BaggingClassifier(base_estimator=DT_MF_clf,n_estimators=100)\n",
    "res=test_clf(X,y,B_MF2_clf)\n",
    "write_answer_to_file(res,\"test1_res4.txt\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ответ в пункте 4 = 0.92986192950280644**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95720427456957058"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier=ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "test_clf(X,y,rf_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5\n",
    "# use a full grid over all parameters\n",
    "param_grid = {#\"max_depth\": [1,5,None],\n",
    "                \"max_depth\": [1,5,10,15,20,None],\n",
    "              #\"max_features\": [1,5,10,15,40,50,60],\n",
    "                \"max_features\": [10],\n",
    "              #\"n_estimators\":[5,10,15,50,80,100,120]\n",
    "                \"n_estimators\":[100]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid=param_grid)\n",
    "grid_search.fit(X, y)\n",
    "scores=pandas.DataFrame(columns=['mean','max_depth','max_features','n_estimators'])\n",
    "i=0\n",
    "for item in grid_search.grid_scores_:\n",
    "    scores.loc[i]=[item[1],item[0]['max_depth'],item[0]['max_features'],item[0]['n_estimators']]\n",
    "    i=i+1\n",
    "scores.head(100)\n",
    "scores.max_depth.fillna('NoLim',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.648303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.903172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.941569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.939900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.938230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoLim</td>\n",
       "      <td>0.939343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max_depth      mean\n",
       "0         1  0.648303\n",
       "1         5  0.903172\n",
       "2        10  0.941569\n",
       "3        15  0.939900\n",
       "4        20  0.938230\n",
       "5     NoLim  0.939343"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=scores.groupby(['max_depth'],as_index =False)['mean'].mean()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.885086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features      mean\n",
       "0          10.0  0.885086"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=scores.groupby(['max_features'],as_index =False)['mean'].mean()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.885086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators      mean\n",
       "0         100.0  0.885086"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=scores.groupby(['n_estimators'],as_index =False)['mean'].mean()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(\"2 3 4 7\",\"test1_res5.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответы в п.5 = 2 3 4 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Нет\n",
    "Случайный лес сильно переобучается с ростом количества деревьев\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Да\n",
    "При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Да\n",
    "С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для \n",
    "высокого качества классификации, а затем качество существенно не меняется.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Да\n",
    "При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, \n",
    "чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле,\n",
    "тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), \n",
    "и тем лучше работает их композиция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Нет\n",
    "При большом количестве признаков (40, 50, 60) качество классификации лучше, ч\n",
    "ем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - \n",
    "тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Нет\n",
    "При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, \n",
    "чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Да\n",
    "При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, \n",
    "чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, \n",
    "а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность \n",
    "в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении\n",
    "они компенсируют переобученность друг-друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
